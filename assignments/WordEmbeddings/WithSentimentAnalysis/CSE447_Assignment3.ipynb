{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLtkZvUChSiA"
      },
      "source": [
        "# Assignment 3: Lexical Semantics and Word Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes about the autograder for this assignment:**\n",
        "\n",
        "*   To submit the coding part of this assignment to Gradescope, download your .ipynb notebook in .ipynb form and submit **only** this file. It must be named **CSE447_Assignment3.ipynb** in order for the autograder to work.\n",
        "*   At a low-load time on Gradescope, the autograder for this assignment takes about **six minutes** to run. We recommend submitting the code part of your assignment with enough time before the deadline to allow the autograder to run, and for you to investigate/correct any issues it flags.\n",
        "*   If you find that only **one** WEAT test is failing, we've seen this happen before (rarely, but it has happened) with a notebook that passes the same test on a different run. If that happens to you, and you're pretty sure that your code isn't the issue, try resubmitting your notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "engQ9C3Af4bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# get any other necessary files for this project\n",
        "\n",
        "if [ ! -e \"data-needed.txt\" ]; then\n",
        "  if [ ! -e \"data_path_to_download_url.py\" ]; then\n",
        "    wget https://raw.githubusercontent.com/serrano-s/NLPassignments-students/refs/heads/main/data_path_to_download_url.py\n",
        "  else\n",
        "    echo \"data_path_to_download_url.py script already downloaded to runtime\"\n",
        "  fi\n",
        "\n",
        "  wget https://raw.githubusercontent.com/serrano-s/NLPassignments-students/refs/heads/main/assignments/WordEmbeddings/WithSentimentAnalysis/data-needed.txt\n",
        "\n",
        "  # download all data files needed for the student-release version of this project (i.e., no hidden test files)\n",
        "  DATA_NEEDED_FILE=\"data-needed.txt\"\n",
        "  closing_slash=\"/\"\n",
        "  while IFS= read -r line; do\n",
        "    line=\"$(echo -e \"${line}\" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')\";\n",
        "    dirs_to_check=\"${line%${closing_slash}*}\"\n",
        "    mkdir -p $dirs_to_check\n",
        "    download_url=$(python data_path_to_download_url.py \"$line\")\n",
        "    echo $download_url;\n",
        "    wget \"$download_url\" -O \"$line\"\n",
        "  done < \"$DATA_NEEDED_FILE\"\n",
        "else\n",
        "  echo \"data-needed.txt (and presumably therefore all necessary data files) already downloaded to runtime\"\n",
        "fi\n",
        "\n",
        "if [ ! -e \"other-setup-needed.sh\" ]; then\n",
        "  wget https://raw.githubusercontent.com/serrano-s/NLPassignments-students/refs/heads/main/assignments/WordEmbeddings/WithSentimentAnalysis/other-setup-needed.sh\n",
        "  bash other-setup-needed.sh\n",
        "  rm data_path_to_download_url.py\n",
        "else\n",
        "  echo \"other-setup-needed.sh (and presumably therefore all other necessary files) already downloaded to runtime\"\n",
        "fi"
      ],
      "metadata": {
        "id": "XW25-eM5ekaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtJJRz73hSiD"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Install required packages\n",
        "\n",
        "pip install pandas\n",
        "\n",
        "pip install sentence-transformers\n",
        "\n",
        "pip install --upgrade ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enujFkehhSiE"
      },
      "outputs": [],
      "source": [
        "# Make sure to always run this\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGhXqROFhSiE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import List, Tuple, Dict, Union\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from wordvec_tests import (\n",
        "    load_synonyms_data,\n",
        "    Exercise1Runner,\n",
        "    Exercise2Runner,\n",
        "    Exercise3aRunner,\n",
        "    Exercise3bRunner,\n",
        "    Exercise4Runner,\n",
        "    Exercise5Runner,\n",
        "    Exercise6Runner\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uM49I3ohSiF"
      },
      "outputs": [],
      "source": [
        "parent_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "data_dir = os.path.join(parent_dir, \"data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZievDbROhSiF"
      },
      "source": [
        "## Part 1: Geometry of Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc4kw-i2hSiF"
      },
      "source": [
        "We provide a helper class to access the glove vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O912Q4c7hSiG"
      },
      "outputs": [],
      "source": [
        "class GloveEmbeddings:\n",
        "\n",
        "    def __init__(self, path=\"embeddings/glove.6B/glove.6B.50d.txt\"):\n",
        "        self.path = path\n",
        "        self.vec_size = int(re.search(r\"\\d+(?=d)\", path).group(0))\n",
        "        self.embeddings = {}\n",
        "        self.load()\n",
        "\n",
        "    def load(self):\n",
        "        for line in open(self.path, \"r\"):\n",
        "            values = line.split()\n",
        "\n",
        "            word_len = len(values) - self.vec_size\n",
        "\n",
        "            word = \" \".join(values[:word_len])\n",
        "            vector_values = list(map(float, values[word_len:]))\n",
        "\n",
        "            word = values[0]\n",
        "            vector_values = list(map(float, values[-self.vec_size:]))\n",
        "            vector = torch.tensor(vector_values, dtype=torch.float)\n",
        "            self.embeddings[word] = vector\n",
        "\n",
        "    def is_word_in_embeddings(self, word):\n",
        "        return word in self.embeddings\n",
        "\n",
        "    def get_vector(self, word):\n",
        "        if not self.is_word_in_embeddings(word):\n",
        "            return self.embeddings[\"unk\"]\n",
        "        return self.embeddings[word]\n",
        "\n",
        "    # Use square operator to get the vector of a word\n",
        "    def __getitem__(self, word):\n",
        "        return self.get_vector(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMiUJK3whSiH"
      },
      "outputs": [],
      "source": [
        "glove_vectors = GloveEmbeddings(\n",
        "    path=f\"{data_dir}/embeddings/glove.6B/glove.6B.50d.txt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iPeQ5WqhSiH"
      },
      "source": [
        "You can simply use `glove_vectors[<word>]` to get the vector for a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nsgt66chSiI"
      },
      "outputs": [],
      "source": [
        "vector = glove_vectors[\"the\"]\n",
        "print(vector.shape)\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdWJduyHhSiI"
      },
      "outputs": [],
      "source": [
        "print(glove_vectors[\"unk\"].shape)\n",
        "print(glove_vectors[\"the\"].shape)\n",
        "print(glove_vectors[\"king\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui_39Z_PhSiJ"
      },
      "source": [
        "Notice that we have a 50 dimensional vector for each word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WniuhKmAhSiJ"
      },
      "source": [
        "### Exercise 1: Synonyms\n",
        "\n",
        "This part is adapted from Dan Jurafsky's NLP class CS124 at Stanford."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmKuAPQGhSiJ"
      },
      "outputs": [],
      "source": [
        "dev_synonyms_df = load_synonyms_data(\"dev\", data_dir=data_dir)\n",
        "dev_synonyms_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rtlEtL6hSiJ"
      },
      "source": [
        "The task is to choose the synonym for a given word from a list of choices. We will use Glove embeddings to find the closest word in the embedding space.\n",
        "\n",
        "There are different metrics to obtain distance / similarity between two vectors in n-dimensional space. These include:\n",
        "\n",
        "1. Euclidean Distance: $d(u, v)  = ||u - v||_2$\n",
        "2. Manhattan Distance: $d(u, v) = ||u - v||_1$\n",
        "3. Cosine Similarity: $s(u, v) = \\frac{u \\cdot v}{||u||_2 ||v||_2}$\n",
        "\n",
        "where $u$ and $v$ are vectors.\n",
        "\n",
        "You will implement a function `find_synonym` that for a word finds the closest synonym from a list of words. The method also receives a distance / similarity metric to use. The function should return the synonym and the value of the metric for the closest word.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-43b7e6c16ca77714",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2rS5K3J4hSiK"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1: torch.Tensor, v2: torch.Tensor) -> float:\n",
        "    \"\"\"\n",
        "    Compute the cosine similarity between two vectors.\n",
        "\n",
        "    Inputs:\n",
        "    v1: torch.Tensor of shape (n,)\n",
        "    v2: torch.Tensor of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "    float: cosine similarity between v1 and v2\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def euclidean_distance(v1: torch.Tensor, v2: torch.Tensor) -> float:\n",
        "    \"\"\"\n",
        "    Compute the Euclidean distance between two vectors.\n",
        "\n",
        "    Inputs:\n",
        "    v1: torch.Tensor of shape (n,)\n",
        "    v2: torch.Tensor of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "    float: Euclidean distance between v1 and v2\n",
        "    \"\"\"\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def manhattan_distance(v1: torch.Tensor, v2: torch.Tensor) -> float:\n",
        "    \"\"\"\n",
        "    Compute the Manhattan distance between two vectors.\n",
        "\n",
        "    Inputs:\n",
        "    v1: torch.Tensor of shape (n,)\n",
        "    v2: torch.Tensor of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "    float: Manhattan distance between v1 and v2\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def find_synonym(\n",
        "    word: str,\n",
        "    choices: List[str],\n",
        "    embeddings: GloveEmbeddings,\n",
        "    metric: str = \"cosine\"\n",
        ") -> Dict[str, Union[str, float]]:\n",
        "\n",
        "    synonym_dict = {\n",
        "        \"synonym\": None,\n",
        "        \"metric\": None\n",
        "    }\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb0kFeDmhSiK"
      },
      "outputs": [],
      "source": [
        "exercise1 = Exercise1Runner(\n",
        "    find_synonym=find_synonym,\n",
        ")\n",
        "\n",
        "exercise1.evaluate(True) #Set False if you only want to see the final accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDeXHl2khSiK"
      },
      "source": [
        "You should expect the dev accuracy to be 83% with cosine similarity metric, 67% with euclidean distance and 70% with manhattan distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddr90zgJhSiL"
      },
      "source": [
        "### Exercise 2: Analogies\n",
        "\n",
        "In this exercise you will use the Linear Representation Hypothesis (check handout to learn about it) to write code that automatically solves the analogy task. As an example:\n",
        "\n",
        "man is to king as woman is to ______ ?\n",
        "\n",
        "a) princess\n",
        "\n",
        "b) queen\n",
        "\n",
        "c) wife\n",
        "\n",
        "d) ruler\n",
        "\n",
        "The task is to find the most appropriate word out of the 4 choices that completes the analogy.\n",
        "\n",
        "This part is adapted from Dan Jurafsky's NLP class CS124 at Stanford."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-cca39233539ddcd4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "YJE6yoh5hSiL"
      },
      "outputs": [],
      "source": [
        "def find_analogy_word(\n",
        "    a: str,\n",
        "    b: str,\n",
        "    aa: str,\n",
        "    choices: List[str],\n",
        "    embeddings: GloveEmbeddings,\n",
        "):\n",
        "\n",
        "    \"\"\"\n",
        "    Given the analogy relation a is to aa as b is to ____, find the word from choices that completes the analogy.\n",
        "    e.g. man is to king as woman is to ____?\n",
        "    a) princess\n",
        "    b) queen\n",
        "    c) wife\n",
        "    d) ruler\n",
        "\n",
        "    Note: Use cosine similarity as the metric for this function.\n",
        "\n",
        "    Inputs:\n",
        "    - a, b, aa: The words in the analogy relation\n",
        "    - choices: A list of words to choose from\n",
        "    - embeddings: GloveEmbeddings object\n",
        "\n",
        "    Returns:\n",
        "     str: The word from choices that best completes the analogy\n",
        "    \"\"\"\n",
        "\n",
        "    answer = None\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v5-qnv9hSiL"
      },
      "outputs": [],
      "source": [
        "exercise2 = Exercise2Runner(find_analogy_word=find_analogy_word)\n",
        "exercise2.evaluate(True) #Set False if you only want to see the final accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PoKc8LDhSiL"
      },
      "source": [
        "You should see an accuracy of 64%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2L91jYghSiM"
      },
      "source": [
        "### Exercise 3: Bias in Word Embeddings\n",
        "\n",
        "We will now implement the Word Embedding Association Test (WEAT) to identify biases in word embeddings. Check the handout for a detailed explanation of the test. You will start by implementing the *Effect Size* metric by implementing the functions:\n",
        "\n",
        "- `word_association_wth_attribute`\n",
        "- `weat_effect_size`\n",
        "\n",
        "`word_association_wth_attribute` computes $s(w, A, B)$ for a given word $w$ and attributes $A$ and $B$, i.e. the association of the word with the attributes. Recall that this is given by:\n",
        "\n",
        "$$s(w, A, B) = \\text{mean}_{a \\in A}\\text{cos}(\\vec{w}, \\vec{a}) - \\text{mean}_{b \\in B} (\\vec{w}, \\vec{b})$$\n",
        "\n",
        "The effect size is then given as:\n",
        "\n",
        "$$\\text{effect-size} = \\frac{\\text{mean}_{x \\in X} s(x, A, B) - \\text{mean}_{y \\in Y} s(y, A, B)}{\\text{std-dev}_{w \\in X \\cup Y} s(w, A, B)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFaUKSchhSiM"
      },
      "outputs": [],
      "source": [
        "with open(f\"{data_dir}/weat/weat.json\", \"r\") as f:\n",
        "    weat_data = json.load(f)\n",
        "\n",
        "weat_data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f9912fe6a11c2388",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FoK0DC1ThSiM"
      },
      "outputs": [],
      "source": [
        "def word_association_wth_attribute(\n",
        "    word: str,\n",
        "    A: List[str],\n",
        "    B: List[str],\n",
        "    embeddings: GloveEmbeddings,\n",
        ") -> float:\n",
        "\n",
        "    \"\"\"\n",
        "    Finds the association of a word in the emedding space with the two sets of attribute words.\n",
        "    E.g. Given the word \"rose\", a set of pleasant words A and unpleasant words B, the function finds if its degree of association to A vs B.\n",
        "\n",
        "    Inputs:\n",
        "    - word: The word for which we want to find the association\n",
        "    - A: List of words representing the first set of attributes\n",
        "    - B: List of words representing the second set of attributes\n",
        "\n",
        "    Returns:\n",
        "    float: The association of the word with the two sets of attributes\n",
        "    \"\"\"\n",
        "\n",
        "    association = None\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "    return association\n",
        "\n",
        "def weat_effect_size(\n",
        "    X: List[str],\n",
        "    Y: List[str],\n",
        "    A: List[str],\n",
        "    B: List[str],\n",
        "    embeddings: GloveEmbeddings,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Compute the effect size of the WEAT test.\n",
        "\n",
        "    Inputs:\n",
        "    - X: List of target words for which we want to find the association.\n",
        "    - Y: List of target words for which we want to find the association.\n",
        "    - A: List of words representing the first set of attributes\n",
        "    - B: List of words representing the second set of attributes\n",
        "    - embeddings: GloveEmbeddings object\n",
        "    \"\"\"\n",
        "\n",
        "    X_associations = torch.mean(torch.tensor([word_association_wth_attribute(x, A, B, embeddings) for x in X]))\n",
        "    Y_associations = torch.mean(torch.tensor([word_association_wth_attribute(y, A, B, embeddings) for y in Y]))\n",
        "\n",
        "    XY = list(set(X).union(set(Y)))\n",
        "    XY_associations_std = torch.std(torch.tensor([word_association_wth_attribute(xy, A, B, embeddings) for xy in XY]))\n",
        "\n",
        "    return ((X_associations - Y_associations) / XY_associations_std).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8Wr65KMhSiM"
      },
      "outputs": [],
      "source": [
        "exercise3 = Exercise3aRunner(\n",
        "    weat_effect_size=weat_effect_size,\n",
        ")\n",
        "exercise3.evaluate_effect_size(\n",
        "    True\n",
        ")  # Set False if you only want to see the final effect sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STL8AEI9hSiM"
      },
      "source": [
        "You should observe the following numbers:\n",
        "\n",
        "\n",
        "Effect size for Flowers-Insects Pleasant Unpleasant case: 1.07782\n",
        "\n",
        "Effect size for MusicalInstruments-Weapons Pleasant Unpleasant case: 1.54396\n",
        "\n",
        "Effect size for EuropeanAmerican AfricanAmerican_Pleasant_Unpleasant case: 1.00395\n",
        "\n",
        "Effect size for Male_Female Career_Family case : 1.70778\n",
        "\n",
        "Effect size for Math_Art Male_Female case : 1.49513"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtnziJpXhSiM"
      },
      "source": [
        "We will now check how statistically significant are these effect sizes. You will implement the function `target_words_diff_association_wth_attribute` which calculates the value of the test statistic: $s(X, Y, A, B)$. Recall this is given by:\n",
        "\n",
        "$$    s(X, Y, A, B) = \\sum_{x \\in X} s(x, A, B) - \\sum_{y \\in Y} s(y, A, B)$$\n",
        "\n",
        "We then use this function to calculate the p-value of the permutation test. We provide you the implementation of the function `weat_p_value`. We recommend you to go through the code to understand how the p-value is calculated, even though you are not supposed to implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6a278538b8bd1047",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "43_fg74PhSiM"
      },
      "outputs": [],
      "source": [
        "def target_words_diff_association_wth_attribute(\n",
        "    X: List[str],\n",
        "    Y: List[str],\n",
        "    A: List[str],\n",
        "    B: List[str],\n",
        "    embeddings: GloveEmbeddings,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Finds the differential association of words in X with the attribute sets A and B vs the words in Y with the attribute sets A and B.\n",
        "\n",
        "    E.g. X can be flower names and Y can be insect names.A can be pleasant words and B can be unpleasant words.\n",
        "    The function measures the difference in total association of flower names and insect names with sets A and B.\n",
        "\n",
        "\n",
        "    Inputs:\n",
        "    - words: List of target words for which we want to find the association.\n",
        "    - A: List of words representing the first set of attributes\n",
        "    - B: List of words representing the second set of attributes\n",
        "    - embeddings: GloveEmbeddings object\n",
        "    \"\"\"\n",
        "\n",
        "    diff_association = None\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "    return diff_association\n",
        "\n",
        "\n",
        "def weat_p_value(\n",
        "    X: List[str],\n",
        "    Y: List[str],\n",
        "    A: List[str],\n",
        "    B: List[str],\n",
        "    embeddings: GloveEmbeddings,\n",
        "    max_permutations: int = 1000,\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Compute the p-values of the WEAT test.\n",
        "\n",
        "    Inputs:\n",
        "    - X: List of target words for which we want to find the association.\n",
        "    - Y: List of target words for which we want to find the association.\n",
        "    - A: List of words representing the first set of attributes\n",
        "    - B: List of words representing the second set of attributes\n",
        "    - embeddings: GloveEmbeddings object\n",
        "    \"\"\"\n",
        "\n",
        "    from sympy.utilities.iterables import multiset_permutations\n",
        "    import numpy as np\n",
        "    diff_association = target_words_diff_association_wth_attribute(X, Y, A, B, embeddings)\n",
        "\n",
        "    target_words = X + Y\n",
        "    # print(len(target_words))\n",
        "\n",
        "    partition_idx = np.zeros(len(target_words))\n",
        "    partition_idx[:len(target_words) // 2] = 1\n",
        "\n",
        "    partition_dff_associations = []\n",
        "    for _ in range(max_permutations):\n",
        "        if len(partition_dff_associations) >= max_permutations:\n",
        "            break\n",
        "        i = np.random.permutation(partition_idx)\n",
        "        X_perm = [target_words[j] for j in range(len(target_words)) if i[j] == 1]\n",
        "        Y_perm = [target_words[j] for j in range(len(target_words)) if i[j] == 0]\n",
        "        partition_dff_associations.append(\n",
        "            target_words_diff_association_wth_attribute(\n",
        "                X_perm, Y_perm, A, B, embeddings\n",
        "            )\n",
        "        )\n",
        "    return np.sum(np.array(partition_dff_associations) > diff_association) / len(\n",
        "        partition_dff_associations\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jgU__6ehSiM"
      },
      "outputs": [],
      "source": [
        "exercise3b = Exercise3bRunner(\n",
        "    weat_p_value=weat_p_value,\n",
        ")\n",
        "\n",
        "exercise3b.evaluate(True) #Set False if you only want to see the final p-values # This might take a while to run (1 minute during our testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5JTJ93khSiN"
      },
      "source": [
        "You should see p-values as 0.0 for all the cases (note that this is approximate since we are not exhaustively considering all the permutations and only considering 1000 random permutations. But the actual p-value should be very close to 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL2VBJKihSiN"
      },
      "source": [
        "### Useful pointers for write up question 3 in 1.1.3 of handout:\n",
        "\n",
        "Glove embeddings of size {{vec_dim}} (e.g. 50) trained on {{num_tokens}} (e.g. 6B) can be loaded as:\n",
        "\n",
        "```\n",
        "glove_vectors = load_glove_vectors(\n",
        "    f\"{data_dir}/embeddings/glove.6B/glove.WEAT.6B.50d.txt\",\n",
        ")\n",
        "```\n",
        "\n",
        "where you change the values of 6B and 50 based on the size of the embeddings and number of tokens used in training.\n",
        "\n",
        "To load weat data of a particular category, you can use the following code:\n",
        "\n",
        "```\n",
        "category = \"Flowers_Insects_Pleasant_Unpleasant\" # Change this to the category you want to load\n",
        "\n",
        "weat_category_data = weat_data[category]\n",
        "\n",
        "X = weat_category_data[\"X\"]\n",
        "Y = weat_category_data[\"Y\"]\n",
        "A = weat_category_data[\"A\"]\n",
        "B = weat_category_data[\"B\"]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRaDIwT7hSiN"
      },
      "outputs": [],
      "source": [
        "# <NO_AUTOGRADE> <=== Leave this code cell as is, otherwise the autograder will have trouble processing your submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc1PgpnChSiN"
      },
      "outputs": [],
      "source": [
        "# We will get glove vectors for all the words of interest and save them in a txt file\n",
        "\n",
        "def save_glove_vectors(words_of_interest, path=\"data/embeddings\", vec_size=50, num_tokens=\"6B\"):\n",
        "\n",
        "    glove_path = f\"{path}/glove.{num_tokens}/glove.{num_tokens}.{vec_size}d.txt\"\n",
        "    all_glove_embeddings = GloveEmbeddings(glove_path)\n",
        "\n",
        "    out_dir = f\"{path}/glove.{num_tokens}/\"\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "\n",
        "    out_path = f\"{out_dir}/glove.WEAT.{num_tokens}.{vec_size}d.txt\"\n",
        "    with open(out_path, \"w\") as f:\n",
        "        for word in words_of_interest:\n",
        "            vector = all_glove_embeddings[word]\n",
        "            f.write(f\"{word} {' '.join([str(v) for v in vector.tolist()])}\\n\")\n",
        "\n",
        "    print(f\"Saved embeddings to {out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIBvPgL5hSiP"
      },
      "outputs": [],
      "source": [
        "# Leave this code cell as is, otherwise the autograder will have trouble processing your submission\n",
        "# </NO_AUTOGRADE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcmkiGV_hSiP"
      },
      "source": [
        "## Part 2: From Word Embeddings to Sentence Level Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iozErPUhhSiP"
      },
      "source": [
        "### Exercise 3.1 Sentence Similarity\n",
        "\n",
        "*This part is adapted from Dan Jurafsky's NLP class CS124 at Stanford.*\n",
        "\n",
        "In this exercise you will be building sentence level representations using word embeddings and then use them to find similarity between two sentences. In particular your goal is to answer questions of the form:\n",
        "\n",
        "```\n",
        "    True/False: the following two sentences are semantically similar:\n",
        "      1. he later learned that the incident was caused by the concorde's sonic boom\n",
        "      2. he later found out the alarming incident had been caused by concorde's powerful sonic boom\n",
        "```\n",
        "\n",
        "To build sentence level representations, you will use the following approaches:\n",
        "\n",
        "* **Simple sum**: Simply take the sum of word embeddings of all words in the sentence\n",
        "* **Sum with POS weighting**: Take a weighted sum of the individual word vectors, where the weight of each word depends on the part of speech tag (POS) of the word.\n",
        "\n",
        "Specifically, you will implement the following functions:\n",
        "* **get_sentence_embedding()**: given a sentence (string), return the sentence embedding (vector). The function also takes in the parameter `use_POS`:\n",
        "    * if `use_POS` is false (regular case), leverage method 1 above - simply the sum of the word embeddings for each word in the sentence (ignoring words that don’t appear in our vocabulary).\n",
        "    * if `use_POS` is true, leverage method 2 - use a weighted sum, where we weight each word by a scalar that depends on its part of speech tag.\n",
        "* **get_sentence_similarity()**: given two sentences, find the cosine similarity between their corresponding sentence embeddings.\n",
        "\n",
        "Helpful hints:\n",
        "\n",
        "* Lowercase all words in the sentence before you look them up in the embeddings. The Glove embeddings that we are using have all words in lowercase.\n",
        "\n",
        "* We’ve given you a map `POS_weights` that maps part of speech tags to their associated weight. For example, `POS_weights['NN'] = 0.8` (where NN is the POS tag for noun).\n",
        "* You may skip words that either (1) are not in our embeddings or (2) have a POS tag that is not in `POS_weights` . To check if a word is not in our embeddings, you can use the following code snippet:\n",
        "\n",
        "```\n",
        "    if glove_vectors.is_word_in_embeddings(word):\n",
        "        # word is in embeddings\n",
        "    else:\n",
        "        # word is not in embeddings\n",
        "```\n",
        "* To get a list of all the words in the sentence, use nltk's word_tokenize function.\n",
        "\n",
        "  ```\n",
        "  >>> sentence = \"this is a sentence\"\n",
        "  >>> word_tokens = word_tokenize(sentence)\n",
        "  >>> word_tokens\n",
        "  ['this', 'is', 'a', 'sentence']\n",
        "  ```\n",
        "\n",
        "* We’ve given you a map `POS_weights` that maps part of speech tags to their associated weight. For example, `POS_weights['NN'] = 0.8` (where NN is the POS tag for noun).\n",
        "* You may skip words that either (1) are not in our embeddings or (2) have a POS tag that is not in `POS_weights` .\n",
        "* To get a list of all the words in the sentence, use nltk's word_tokenize function.\n",
        "\n",
        "  ```\n",
        "  >>> sentence = \"this is a sentence\"\n",
        "  >>> word_tokens = word_tokenize(sentence)\n",
        "  >>> word_tokens\n",
        "  ['this', 'is', 'a', 'sentence']\n",
        "  ```\n",
        "\n",
        "  * To get the POS tags for each word in a sentence, you can use nltk.pos_tag. To use it, you provide a list of words in a sentence, and it returns a list of tuples, where the first element is the word and the second is its corresponding POS tag. **For this PA, make sure that you pass in the entire sentence to a single call to nltk.pos_tag; do not call  nltk.pos_tag separately on each word in the sentence.** This is because some words can be multiple parts of speech (for example, \"back\" can be a noun or a verb). Passing in the entire sentence allows for more context to figure out what POS tag a word should have.\n",
        "\n",
        "```\n",
        "    >>> tagged_words = nltk.pos_tag(word_tokens)\n",
        "    >>> tagged_words\n",
        "    [('this', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sentence', 'NN')]`\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Gi2A62yhSiQ"
      },
      "outputs": [],
      "source": [
        "# You will use nltk for tokenizing and tagging!\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emhKhjR4hSiQ"
      },
      "outputs": [],
      "source": [
        "# Run this cell to download the nltk tagger\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F32OR7IAhSiQ"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load POS Weights\n",
        "with open(f\"{data_dir}/pos_weights.txt\", \"r\") as f:\n",
        "    pos_weights = f.read().split(\"\\n\")\n",
        "    pos_weights = {line.split()[0]: float(line.split()[1]) for line in pos_weights}\n",
        "print(pos_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTUdZnhEhSiQ"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the dataset\n",
        "sentence_df = pd.read_csv(f\"{data_dir}/sentence_similarity/dev.csv\", sep=\"\\t\", header=None, names=[\"label\", \"sentence1\", \"sentence2\"])\n",
        "sentence_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-be5072e87b06b828",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "DXmm-UpXhSiR"
      },
      "outputs": [],
      "source": [
        "def get_sentence_embedding(\n",
        "    sentence: str,\n",
        "    word_embeddings: GloveEmbeddings,\n",
        "    use_POS: bool = False,\n",
        "    pos_weights: Dict[str, float] = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute the sentence embedding using the word embeddings.\n",
        "\n",
        "    Inputs:\n",
        "    - sentence: The input sentence\n",
        "    - word_embeddings: GloveEmbeddings object\n",
        "    - use_POS: Whether to use POS tagging\n",
        "    - pos_weights: Dictionary containing POS weights\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The sentence embedding\n",
        "    \"\"\"\n",
        "\n",
        "    sentence_embedding = None\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "\n",
        "def get_sentence_similarity(\n",
        "    sentence1: str,\n",
        "    sentence2: str,\n",
        "    word_embeddings: GloveEmbeddings,\n",
        "    use_POS: bool = False,\n",
        "    pos_weights: Dict[str, float] = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute the similarity between two sentences.\n",
        "\n",
        "    Inputs:\n",
        "    - sentence1: The first input sentence\n",
        "    - sentence2: The second input sentence\n",
        "    - word_embeddings: GloveEmbeddings object\n",
        "    - use_POS: Whether to use POS tagging\n",
        "    - pos_weights: Dictionary containing POS weights\n",
        "\n",
        "    Returns:\n",
        "    float: The similarity between the two sentences\n",
        "    \"\"\"\n",
        "\n",
        "    similarity = None\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfV591XthSiS"
      },
      "outputs": [],
      "source": [
        "exercise4 = Exercise4Runner(\n",
        "    get_sentence_similarity=get_sentence_similarity,\n",
        ")\n",
        "\n",
        "exercise4.evaluate(True) #Set False if you only want to see the final accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42Lrp5PfhSiS"
      },
      "source": [
        "Note that our tester is using a threshold of 0.95 for the similarity score, i.e. we consider the prediction as 1 if cosine similarity return by your function is greater than 0.95, else consider it as 0. You should expect the following accuracies:\n",
        "\n",
        "accuracy using sum of word vectors : 0.85\n",
        "\n",
        "accuracy using sum of word vectors with POS weights : 0.925"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Qj9KAxhSiS"
      },
      "source": [
        "### Exercise 5. K-Nearest Neighbors Classifier using Glove-Based Sentence Embeddings\n",
        "\n",
        "We will now utilize the sentence representations to build a K-Nearest Neighbors (KNN) classifier. A KNN classifier classifies a sentence by finding its nearest neighbors (in the embedding space) in the training data and taking a majority vote of the labels of neighbors.\n",
        "\n",
        "\n",
        " We will be working with the SST dataset from HW1, i.e. classifying the sentiment of movie reviews (we will consider both binary and 5-class classification case). You will implement the following class:\n",
        "\n",
        "`GloveKNNClassifier` with methods:\n",
        "- `__init__`: Initialize the classifier with the value of k and the choice of sentence embedding method (simple sum or sum with POS weights)\n",
        "- `fit`: Calculates the sentence embeddings for all sentences in the training data and stores them. Also stores the corresponding labels.\n",
        "- `predict`: Predicts the label(s) for the given sentence(s) using the K-Nearest Neighbors algorithm. The distance metric to use is cosine similarity.\n",
        "\n",
        "Helpful Tips:\n",
        "\n",
        "- Lower case the training as well as test sentences before computing their embeddings (if your `get_sentence_embedding` already handles that for you, you don't need to do it again here)\n",
        "\n",
        "- To avoid division by zero when calculating cosine similarity, you can add a small epsilon value i.e. 1e-8 to the denominator.\n",
        "\n",
        "- We strongly recommend implementing a vectorized version of `cosine_similarity` here, i.e. instead of one by one computing similarity between a test sentence and a training sentence, implement a function which takes n test sentences and m train sentences and uses matrix multiplication operations to get a similarity matrix of shape [n, m]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-8acd336bbcd41c82",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ykYOxt93hSiS"
      },
      "outputs": [],
      "source": [
        "class GloveKNNClassifier:\n",
        "\n",
        "    def __init__(self, word_embeddings: GloveEmbeddings, k: int = 5, use_POS: bool = False, pos_weights: Dict[str, float] = None):\n",
        "        \"\"\"\n",
        "        Initialize the KNN Classifier.\n",
        "        Inputs:\n",
        "        - word_embeddings: GloveEmbeddings object\n",
        "        - k: Number of nearest neighbors to consider\n",
        "        - use_POS: Whether to use POS tag based weights for the embeddings\n",
        "        - pos_weights: Dictionary containing POS weights\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def fit(self, X_train: List[str], y_train: List[int]):\n",
        "        \"\"\"\n",
        "        Fit the KNN Classifier by calculating the sentence embeddings for the training sentences and storing them. Also store the corresponding labels.\n",
        "        Inputs:\n",
        "        - X_train: List of training sentences (documents)\n",
        "        - y_train: List of corresponding labels\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict(self, X_test: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Predicts the labels for the test sentences using the training data embeddings.\n",
        "\n",
        "        Inputs:\n",
        "        - X_test: List of test sentences\n",
        "\n",
        "        Returns:\n",
        "        - List of predicted labels\n",
        "\n",
        "        Hint: `torch.topk` might be useful here.\n",
        "        \"\"\"\n",
        "\n",
        "        y_pred = None\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    # Any extra functions you need can be added here\n",
        "\n",
        "    # YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-EqjPqLhSiS"
      },
      "outputs": [],
      "source": [
        "exercise5 = Exercise5Runner(GloveKNNClassifier)\n",
        "exercise5.evaluate(k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63sB-pRchSiS"
      },
      "source": [
        "Using $k=5$, you should see the following accuracies:\n",
        "\n",
        "Binary Classification:\n",
        "- Train accuracy using sum of word vectors : 0.76884\n",
        "- Dev accuracy using sum of word vectors with POS weights : 0.65849\n",
        "\n",
        "- Train accuracy using sum of word vectors with POS weights : 0.77142\n",
        "- Dev accuracy using sum of word vectors with POS weights : 0.63397\n",
        "\n",
        "Multi-class Classification:\n",
        "- Train accuracy using sum of word vectors : 0.52037\n",
        "- Dev accuracy using sum of word vectors with POS weights : 0.30609\n",
        "\n",
        "- Train accuracy using sum of word vectors with POS weights : 0.52095\n",
        "- Dev accuracy using sum of word vectors with POS weights : 0.27611\n",
        "\n",
        "A good way to debug your code can be to check if you get 100% train accuracies for all the cases when you use `k = 1`, since the closest point to a point is the point itself. You can check that by running:\n",
        "\n",
        "```\n",
        "exercise5.evaluate(k=1)\n",
        "```\n",
        "\n",
        "**Note**: You'll need to decide how to handle ties between different first-place labels aggregated from neighboring instances. While in principle, any way of doing this is fine, if you want to match our numbers, use `torch.mode` to do so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYMwcOn0hSiT"
      },
      "source": [
        "You may have noticed that the nearest neighbor classifier with glove embeddings doesn't perform very well, in fact it performs worse than the the linear classifiers we trained in HW1. One of the reasons why this happens is because the way we construct the sentence embeddings by summing the word embeddings. Can you think of the issues with such approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x_4NuzBhSiT"
      },
      "source": [
        "### Exercise 6:  K-Nearest Neighbors Classifier using Transformer Based Sentence Embeddings\n",
        "\n",
        "We will now utilize pre-trained transformers based sentence embeddings to build our KNN classifier. These embeddings are trained on large text corpora and learn sentence level representations which are much more powerful than the simple sum of word embeddings.\n",
        "While we haven't covered transformers based sentence embeddings in the class yet, we would like to give you a flavour of how the directly trained sentence level representations can be more powerful. We will be using the `sentence-transformers` library to get the sentence embeddings. Below we provide you with a helper function `get_st_embeddings` which takes in a list of sentences, and a sentence transformers model, and returns the sentence embeddings using the `sentence-transformers` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TksmTqFihSiT"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def get_st_embeddings(sentences: Union[str, List[str]], st_model: SentenceTransformer, batch_size: int = 32):\n",
        "    \"\"\"\n",
        "    Compute the sentence embedding using the Sentence Transformer model.\n",
        "\n",
        "    Inputs:\n",
        "    - sentence: The input sentence\n",
        "    - st_model: Senten ceTransformer model\n",
        "    - batch_size: Encode in batches to avoid memory issues in case multiple sentences are passed\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: The sentence embedding of shape [d,] (when only 1 sentence) or [n, d] where n is the number of sentences and d is the embedding dimension\n",
        "    \"\"\"\n",
        "\n",
        "    sentence_embeddings = None\n",
        "\n",
        "    for i in range(0, len(sentences), batch_size):\n",
        "        batch_sentences = sentences[i:i + batch_size]\n",
        "        # Lowercase the sentences\n",
        "        batch_sentences = [sentence.lower() for sentence in batch_sentences]\n",
        "        batch_embeddings = st_model.encode(batch_sentences, convert_to_tensor=True)\n",
        "        if sentence_embeddings is None:\n",
        "            sentence_embeddings = batch_embeddings\n",
        "        else:\n",
        "            sentence_embeddings = torch.cat([sentence_embeddings, batch_embeddings], dim=0)\n",
        "\n",
        "    return sentence_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwpsYN18hSiT"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "\n",
        "# Load model\n",
        "st_model = SentenceTransformer(\n",
        "    \"all-MiniLM-L6-v2\"\n",
        ")  # You can use any model from the Sentence Transformers library. See the list here: https://sbert.net/docs/sentence_transformer/pretrained_models.html\n",
        "\n",
        "# Get embeddings\n",
        "sent_embeddings = get_st_embeddings(\n",
        "    [\"This is a test sentence\", \"This is another test sentence\"], st_model\n",
        ")\n",
        "print(sent_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ce6c957b6c39d345",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "d6c-Zh_fhSiU"
      },
      "outputs": [],
      "source": [
        "class SentenceTransformerKNNClassifier(GloveKNNClassifier):\n",
        "\n",
        "    def __init__(\n",
        "        self, st_model: str = \"all-mpnet-base-v2\", k: int = 5, batch_size: int = 128\n",
        "    ):\n",
        "\n",
        "        super().__init__(None, k)\n",
        "\n",
        "        self.st_model = SentenceTransformer(st_model)\n",
        "        self.k = k\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X_train: List[str], y_train: List[int]):\n",
        "\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict(self, X_test: List[str]) -> List[int]:\n",
        "\n",
        "        y_pred = None\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F0oeg3AhSiU"
      },
      "outputs": [],
      "source": [
        "# You can first evaluate your implementation on debug mode that only uses a fraction of train and dev sets\n",
        "exercise6 = Exercise6Runner(SentenceTransformerKNNClassifier)\n",
        "exercise6.evaluate(k=10, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPuHocGphSiU"
      },
      "source": [
        "In the debug model you should see a dev accuracy of 0.9 for binary case and 0.3 for multi-class case. Note that these are not the actual accuracy values, but a way to check if your code is running without any errors. Once you are satisfied with the debug accuracies, you can run the code below to get the actual accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHl1bSz5hSiU"
      },
      "outputs": [],
      "source": [
        "# This will take a while to run (can take upto 40 minutes).\n",
        "# You can reduce the runtime by using a GPU runtime and using device=\"cuda\" while calling `get_st_embeddings` function.\n",
        "\n",
        "exercise6 = Exercise6Runner(SentenceTransformerKNNClassifier)\n",
        "exercise6.evaluate(k=10, debug=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7rRx1LehSiU"
      },
      "source": [
        "You should see the following accuracies:\n",
        "\n",
        "Binary Classification:\n",
        "- Dev accuracy: 0.81471\n",
        "\n",
        "Multi-class Classification:\n",
        "- Dev accuracy: 0.42507"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob88r5_OhSiU"
      },
      "source": [
        "As you can see we get much better numbers than the glove embeddings (a 10% improvement). We can further improve these numbers by fine-tuning the transformer model on our specific task, but that is out of the scope of this assignment."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}